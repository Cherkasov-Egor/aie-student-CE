
# HW06 – Report

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: 25000 строк, 60 признаков, столбцов 62 (60+id+target)
- Целевая переменная: `target` - бинарная классификация
- Признаки: 60 числовых признаков, пропусков не обнаружено, сами признаки анонимизированы

## 2. Protocol

- Разбиение: train = 0.8, test = 0.2, random_state = 42
- Подбор: StratifiedKFold (5 фолдов), чтобы сохранить пропорцию редкого класса в каждом фолде, оптимизируемая метрика - roc_auc
- Метрики: ROC-AUC: Основная метрика. Показывает способность модели ранжировать объекты (отделять классы друг от друга), устойчива к дисбалансу. F1-score: Важная метрика для оценки баланса точности и полноты на редком классе (В нашем случае 1). Recall:

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier: Baseline (стратегия most_frequent). Нужен, чтобы оценить "нулевой уровень".

- LogisticRegression: Линейный baseline. Использовалось масштабирование (StandardScaler) и балансировка весов (class_weight='balanced').

- DecisionTreeClassifier: Одиночное дерево.

    Подбирали: max_depth, min_samples_leaf, ccp_alpha, class_weight,.

- RandomForestClassifier: Бэггинг (ансамбль деревьев).

    Подбирали: n_estimators, max_depth, min_samples_leaf, max_features, class_weight

- AdaBoostClassifier: Бустинг.

    Базовый эстиматор: DecisionTree. Подбирали n_estimators, estimator__max_depth и learning_rate.

- StackingClassifier:

    Стекинг лучших версий RF, Boosting и LogReg. Мета-модель: LogisticRegression.

## 4. Results

| Model                     | F1-score | Recall   | Accuracy | ROC-AUC  |
|---------------------------|----------|----------|----------|----------|
|RandomForest               | 0.707692 | 0.560976 | 0.9772   | 0.886052 |
| Stacking                  | 0.743529 | 0.642276 | 0.9782   | 0.885441 |
| AdaBoost                  | 0.544928 | 0.382114 | 0.9686   | 0.874669 |
| LogReg(scaled)            | 0.428571 | 0.280488 | 0.9632   | 0.834512 |
| DecisionTree              | 0.364364 | 0.739837 | 0.8730   | 0.832923 |
| DummyClassifier(most_freq)| 0.000000 | 0.000000 | 0.9508   | 0.500000 |

Победитель: RandomForestClassifier. Модель показала лучший ROC-AUC и сбалансированный F1. Хотя Stacking показал схожие (иногда чуть лучшие) результаты, RF предпочтительнее как более простая и интерпретируемая модель. LogisticRegression дала высокий Recall, но очень низкую Precision (много ложных срабатываний), из-за чего F1 низкий. В целом видно доминирование ансамблей над линейными моделями вполне отчётливо, приросты составляют по roc_auc ~4-5%

## 5. Analysis

- Устойчивость: для анализа были выбраны Random Forest и LogReg. Логистическая регрессия показала куда большее отклонение, чем Random forest, в плане результатов ансамблевая модель показала куда большую устойчивость
- Ошибки: Основная проблема на таком дисбалансе — False Negative, а именно пропуски целевого класса. Random Forest смог правильно классифицировать более половины объектов редкого класса, сохраняя высокую точность на мажоритарном, что является хорошим результатом для таких данных

- Интерпретация: Confusion matrix для RandomForest на тестовой выборке:

True Negative: 4748

False Positive: 6

False Negative: 108

True Positive: 138

Модель практически не допускает ложных срабатываний на отрицательном классе (крайне малое число FP), однако часть объектов положительного класса остаётся нераспознанной (FN > FP). Это указывает на консервативное поведение классификатора при стандартном пороге 0.5: модель предпочитает избегать ложных тревог ценой пропуска части положительных случаев. С учётом дисбаланса классов такая картина ожидаема и объясняет, почему ROC-AUC является более информативной метрикой, чем accuracy.

Для оценки качества модели в условиях сильного дисбаланса классов (≈95/5) была проанализирована Precision–Recall кривая. Её форма соответствует типичному поведению модели в дисбалансной бинарной классификации: при малых значениях recall достигается высокий precision за счёт отбора наиболее уверенных положительных примеров, однако по мере увеличения recall precision закономерно снижается. Значение Average Precision = 0.774 существенно превышает базовый уровень случайной модели, равный доле положительного класса, что указывает на высокое качество ранжирования объектов. Полученная PR-кривая подтверждает, что модель эффективно разделяет классы по score, а итоговый баланс между ложными и пропущенными срабатываниями определяется выбором порога классификации.

Интерпретация (permutation importance): Permutation importance (по снижению ROC-AUC) показывает, что наибольший вклад в качество модели вносят признаки f54, f25, f58, f53 и f38. Перемешивание этих признаков приводит к наибольшему падению ROC-AUC, что говорит об их высокой информативности для задачи классификации.

При этом вклад признаков убывает достаточно плавно, без одного доминирующего фактора. Это типично для случайного леса и говорит о том, что модель опирается на комбинацию признаков, а не на единичный «сильный» сигнал. Такой характер важностей снижает риск переобучения и повышает устойчивость обобщающей способности модели.

## 6. Conclusion

В задаче бинарной классификации с сильным дисбалансом классов (≈95/5) accuracy перестаёт быть информативной метрикой, поэтому для сравнения моделей целесообразно использовать ROC-AUC и F1, учитывающие качество распознавания миноритарного класса.

Одиночные деревья решений склонны к переобучению и нестабильности, тогда как ансамбли на их основе позволяют существенно снизить дисперсию и получить более надёжные результаты на отложенной выборке.

Random Forest показал хорошее качество ранжирования объектов при сохранении устойчивости к выбору random_state, что типично для бэггинг-ансамблей.

Анализ confusion matrix показал перекос в сторону минимизации ложных срабатываний, что при стандартном пороге классификации приводит к пропуску части положительных объектов и подчёркивает важность выбора decision threshold.

Permutation importance позволил интерпретировать вклад признаков даже для ансамблевой модели и показал, что решение основано на комбинации факторов, а не на одном доминирующем признаке.

Честный ML-протокол в условиях дисбаланса требует строгого разделения данных, подбора гиперпараметров только на train и интерпретации всех метрик исключительно на test-наборе.
